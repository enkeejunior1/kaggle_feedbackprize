{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook baseline_object_detection.ipynb to script\n",
      "[NbConvertApp] Writing 34757 bytes to baseline_object_detection.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script baseline_object_detection.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange, repeat, reduce\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmain ref) https://www.kaggle.com/cdeotte/pytorch-bigbird-ner-cv-0-615?scriptVersionId=83230719\\ndetr ref) https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_demo.ipynb\\ndetr ref) https://www.kaggle.com/tanulsingh077/end-to-end-object-detection-with-transformers-detr\\n코드 실행 전 준비 사항 :\\n    1) 먼저 kaggle 에서 데이터를 다운받고, './input' 에 압축해제 시켜준다.\\n    2) detr 을 fork 해준다. # !git clone https://github.com/facebookresearch/detr.git\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "main ref) https://www.kaggle.com/cdeotte/pytorch-bigbird-ner-cv-0-615?scriptVersionId=83230719\n",
    "detr ref) https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_demo.ipynb\n",
    "detr ref) https://www.kaggle.com/tanulsingh077/end-to-end-object-detection-with-transformers-detr\n",
    "코드 실행 전 준비 사항 :\n",
    "    1) 먼저 kaggle 에서 데이터를 다운받고, './input' 에 압축해제 시켜준다.\n",
    "    2) detr 을 fork 해준다. # !git clone https://github.com/facebookresearch/detr.git\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# object detection 문제로 전처리하기\n",
    "# objective : use DETR structure for sentence segmentation.\n",
    "PATH = os.path.join(os.getcwd(), 'input')\n",
    "TRAIN_NER_PATH_DETR = os.path.join(PATH, 'train_detr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo\n",
    "#!# test code for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER label 로 전처리한 데이터 불러오기\n",
    "# 만약 starting class 를 원하지 않는다면 이하 코드를 실행할 것.\n",
    "\n",
    "try:\n",
    "    from ast import literal_eval\n",
    "    train_text_df = pd.read_csv(TRAIN_NER_PATH_DETR)\n",
    "    \n",
    "    # pandas saves lists as string, we must convert back\n",
    "    from ast import literal_eval\n",
    "    train_text_df.segment_label = train_text_df.segment_label.apply(lambda x: literal_eval(x))\n",
    "    \n",
    "    original_train_df = pd.read_csv(os.path.join(PATH, 'train.csv'))\n",
    "    \n",
    "except:\n",
    "    print('this is 1st time to run this code...')\n",
    "    print('try to convert original text to DETR labels...')\n",
    "    # read original text files0\n",
    "    train_ids, train_texts = [], []\n",
    "    for f in tqdm(list(os.listdir(os.path.join(PATH, 'train')))):\n",
    "        train_ids.append(f.replace('.txt', ''))\n",
    "        train_texts.append(open(os.path.join(PATH, 'train', f), 'r').read())\n",
    "    train_text_df = pd.DataFrame({'id': train_ids, 'text': train_texts})\n",
    "\n",
    "    # convert segment label into object detection label : [segment_type, x, y]\n",
    "    original_train_df = pd.read_csv(os.path.join(PATH, 'train.csv'))\n",
    "    label_list = []\n",
    "    for i, text_df in tqdm(train_text_df.iterrows()):\n",
    "        total = text_df['text'].split().__len__()\n",
    "        segment_label_list = []\n",
    "        for j, segment_df in original_train_df[original_train_df['id'] == text_df['id']].iterrows():\n",
    "            segment_label = [\n",
    "                segment_df['discourse_type'],\n",
    "                int(segment_df['predictionstring'].split(' ')[0]), \n",
    "                int(segment_df['predictionstring'].split(' ')[-1])\n",
    "            ]\n",
    "            segment_label_list.append(segment_label)\n",
    "\n",
    "        label_list.append(segment_label_list)\n",
    "\n",
    "    train_text_df['segment_label'] = label_list\n",
    "    train_text_df.to_csv(TRAIN_NER_PATH_DETR, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE DICTIONARIES THAT WE CAN USE DURING TRAIN AND INFER\n",
    "output_labels_detr = [\n",
    "    'O', # detr need dummy class for padding\n",
    "    'Lead', \n",
    "    'Position', \n",
    "    'Claim', \n",
    "    'Counterclaim', \n",
    "    'Rebuttal', \n",
    "    'Evidence', \n",
    "    'Concluding Statement'\n",
    "]\n",
    "\n",
    "labels_to_ids = {v:k for k,v in enumerate(output_labels_detr)}\n",
    "ids_to_labels = {k:v for k,v in enumerate(output_labels_detr)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15594 train texts. We will split 90% 10% for validation.\n",
      "FULL Dataset: (15594, 3)\n",
      "TRAIN Dataset: (14034, 3)\n",
      "VALID Dataset: (1560, 3)\n"
     ]
    }
   ],
   "source": [
    "# CHOOSE VALIDATION INDEXES\n",
    "IDS = original_train_df.id.unique()\n",
    "print('There are',len(IDS),'train texts. We will split 90% 10% for validation.')\n",
    "\n",
    "# TRAIN VALID SPLIT 90% 10%\n",
    "train_idx = np.random.choice(np.arange(len(IDS)),int(0.9*len(IDS)),replace=False)\n",
    "valid_idx = np.setdiff1d(np.arange(len(IDS)),train_idx)\n",
    "\n",
    "# CREATE TRAIN SUBSET AND VALID SUBSET\n",
    "data_df = train_text_df[['id','text', 'segment_label']]\n",
    "train_df = data_df.loc[data_df['id'].isin(IDS[train_idx]),['id', 'text', 'segment_label']].reset_index(drop=True)\n",
    "valid_df = data_df.loc[data_df['id'].isin(IDS[valid_idx])].reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(data_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_df.shape))\n",
    "print(\"VALID Dataset: {}\".format(valid_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Venus', 'is', 'a', 'worthy', 'pursuit', 'despite', 'the', 'dangers.']\n",
      "39834    Venus is a worthy pursuit despite the dangers \n",
      "Name: discourse_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "'''test code for preprocessing'''\n",
    "i = 1\n",
    "j = 0\n",
    "\n",
    "# pre-processed\n",
    "label, start_idx, end_idx = data_df['segment_label'][i][j]\n",
    "text_id = data_df['id'][i]\n",
    "print(data_df['text'][i].split()[start_idx:end_idx+1])\n",
    "\n",
    "# original\n",
    "original_text = original_train_df[original_train_df['id'] == text_id]\n",
    "print(original_text[original_text['discourse_type'] == label]['discourse_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>segment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7301B174090E</td>\n",
       "      <td>I believe that a B average would be a good thi...</td>\n",
       "      <td>[[Position, 0, 14], [Claim, 32, 47], [Counterc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3799E21B6EC3</td>\n",
       "      <td>Venus is a worthy pursuit despite the dangers....</td>\n",
       "      <td>[[Position, 0, 7], [Claim, 8, 28], [Evidence, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29C5DBB0A339</td>\n",
       "      <td>Limiting car usage will have many advantages. ...</td>\n",
       "      <td>[[Position, 0, 6], [Claim, 11, 12], [Claim, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1613BD216385</td>\n",
       "      <td>\"Making Mona Lisa Smile\" is about a computer h...</td>\n",
       "      <td>[[Lead, 0, 39], [Position, 40, 64], [Evidence,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D4A3E7EC982E</td>\n",
       "      <td>In this essay i will be explaining the differe...</td>\n",
       "      <td>[[Lead, 0, 22], [Position, 23, 33], [Claim, 34...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               text  \\\n",
       "0  7301B174090E  I believe that a B average would be a good thi...   \n",
       "1  3799E21B6EC3  Venus is a worthy pursuit despite the dangers....   \n",
       "2  29C5DBB0A339  Limiting car usage will have many advantages. ...   \n",
       "3  1613BD216385  \"Making Mona Lisa Smile\" is about a computer h...   \n",
       "4  D4A3E7EC982E  In this essay i will be explaining the differe...   \n",
       "\n",
       "                                       segment_label  \n",
       "0  [[Position, 0, 14], [Claim, 32, 47], [Counterc...  \n",
       "1  [[Position, 0, 7], [Claim, 8, 28], [Evidence, ...  \n",
       "2  [[Position, 0, 6], [Claim, 11, 12], [Claim, 14...  \n",
       "3  [[Lead, 0, 39], [Position, 40, 64], [Evidence,...  \n",
       "4  [[Lead, 0, 22], [Position, 23, 33], [Claim, 34...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset 이 잘 작동하는지 확인하는 코드\n",
    "# #!# 로 표지된 index 를 바꿔주면 해당 dataset_row 에 대해서 전처리된 라벨과 실제 라벨에서 다른 부분을 출력해준다.\n",
    "\n",
    "# data = data_df\n",
    "# is_train = True\n",
    "\n",
    "# index = 2 #!# 바꾸면서 다양한 시도 해보기\n",
    "\n",
    "# text = data.text[index]        \n",
    "# text_id = data.id[index]\n",
    "# segment_label_list = data.segment_label[index] if is_train else None\n",
    "\n",
    "# # TOKENIZE TEXT\n",
    "# encoding = tokenizer(\n",
    "#     text.split(),\n",
    "#     is_split_into_words=True,\n",
    "#     padding='max_length', #!# need to check exist seq s.t. longer than 4094\n",
    "#     truncation=True, #!# need to check exist seq s.t. longer than 4094\n",
    "#     max_length=500\n",
    "# )\n",
    "        \n",
    "# word_ids = encoding.word_ids()\n",
    "\n",
    "# segment_ids_list = [[labels_to_ids[label], start_idx, end_idx] for label, start_idx, end_idx in segment_label_list]\n",
    "\n",
    "# processed_list = []\n",
    "# for ids, start_idx, end_idx in segment_ids_list:\n",
    "#     start_word_ids = word_ids.index(start_idx)\n",
    "#     end_word_ids = word_ids.index(end_idx)\n",
    "    \n",
    "#     processed_list.append(tokenizer.decode(encoding.input_ids[start_word_ids:end_word_ids+1]))\n",
    "    \n",
    "# original_list = list(train_df[train_df['id'] == text_id]['discourse_text'])\n",
    "\n",
    "# is_same = True\n",
    "# for p_discourse, o_discourse in zip(processed_list, original_list):\n",
    "#     if p_discourse.split() == o_discourse.split():\n",
    "#         continue\n",
    "        \n",
    "#     else: \n",
    "#         is_same = False\n",
    "#         for p, o in zip(p_discourse.split(), o_discourse.split()):\n",
    "#             if p != o:\n",
    "#                 print(p, o)\n",
    "# if is_same:\n",
    "#     print('every token in the label is same.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''baseline : ignore \\n\\n, 문장 기호들'''\n",
    "#!# 문장 기호는 상당히 중요한 정보를 담고 있어서 처리해주고 싶은데.. \n",
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, is_train):\n",
    "        super(dataset, self).__init__()\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.is_train = is_train # if test (or validation) period, we won't use word label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        global max_segment\n",
    "        # GET TEXT AND WORD LABELS \n",
    "        text = self.data.text[index]        \n",
    "        segment_label_list = self.data.segment_label[index] if self.is_train else None\n",
    "\n",
    "        # TOKENIZE TEXT\n",
    "        encoding = self.tokenizer(\n",
    "            text.split(),\n",
    "            is_split_into_words=True,\n",
    "            return_offsets_mapping=False, #!# how to use it for enabling tokenizer to \"see\" \\n\\n?\n",
    "            padding='max_length', #!# need to check exist seq s.t. longer than 4094\n",
    "            truncation=True, #!# need to check exist seq s.t. longer than 4094\n",
    "            max_length=self.max_len\n",
    "        )\n",
    "        \n",
    "        word_ids = encoding.word_ids()\n",
    "        \n",
    "        # CREATE TARGETS\n",
    "        #!# detr label padding 구현 : x, y 정보는 어떻게 넣어주는가? 0이어도 되나, random 이 더 좋으려나\n",
    "        #!# 결론 : padding 은 구현 안함. loss 계산에서 누락. 필요하면 이하 코드 활용.\n",
    "        #!# 근데, 또 null_object weight 같은걸 보면 아예 없지는 않은듯.... 어렵네\n",
    "        if self.is_train:\n",
    "            segment_ids_list = torch.as_tensor([[labels_to_ids[label], start_idx, end_idx] for label, start_idx, end_idx in segment_label_list]) # [num_seg, 3]\n",
    "            segment_ids_pad  = torch.zeros(max_segment - segment_ids_list.size(0), segment_ids_list.size(1)) # [max_seg - num_seg, 3]\n",
    "            segment_ids_list = torch.cat((segment_ids_list, segment_ids_pad), dim = 0) # [max_seg, 3]\n",
    "            encoding['labels'] = segment_ids_list #!# .type(torch.LongTensor) # class, bound box must be long tensor\n",
    "\n",
    "        # CONVERT TO TORCH TENSORS\n",
    "        item = {k: torch.as_tensor(v) for k, v in encoding.items()}\n",
    "        \n",
    "        # id 를 넣어주면 마무리\n",
    "        item['id'] = self.data.id[index]        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref) https://github.com/facebookresearch/detr 를 참고했으나, review 필요함.\n",
    "class DetrHead(nn.Module):\n",
    "    def __init__(self, feature_extractor, transformer, prediction_head, pos_emb, max_seq, max_segment, d_model,device_0, device_1, split_gpus = True):\n",
    "        super(DetrHead, self).__init__()\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.transformer = transformer\n",
    "        self.prediction_head = prediction_head\n",
    "        \n",
    "        self.feature_pos = nn.Parameter(torch.rand(max_seq, d_model)).cuda(device_1) #!# pos_emb # absolute positional encoding (sinusodial, attention is all you need)\n",
    "        self.query_pos = nn.Parameter(torch.rand(max_segment, d_model)).cuda(device_1)\n",
    "        \n",
    "#         self.split_gpus = split_gpus\n",
    "        \n",
    "#         if split_gpus:\n",
    "#             print('split model for parallel processing')\n",
    "#             self.feature_extractor.cuda(0) # LM\n",
    "#             self.query_pos.cuda(1)\n",
    "#             self.feature_pos.cuda(1)\n",
    "#             self.transformer.cuda(1)\n",
    "#             self.prediction_head.cuda(1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.feature_extractor(x) # x -> [b, s, d_model]\n",
    "        out = out.cuda(device_1)\n",
    "        #!# absolute pos : out = self.transformer(out + self.feature_pos(out), repeat(self.query_pos, 'i j -> b i j', b = out.size(0))) # [b, s, d_model]\n",
    "        out = self.transformer(out + repeat(self.feature_pos, 'i j -> b i j', b = out.size(0)), repeat(self.query_pos, 'i j -> b i j', b = out.size(0))) # [b, s, d_model]\n",
    "        out = self.prediction_head(out)\n",
    "        return out\n",
    "    \n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, lm):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.lm = lm\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.lm(input_ids = x['input_ids'], attention_mask = x['attention_mask']).last_hidden_state #!# todo : try other layer\n",
    "        return out\n",
    "    \n",
    "class Transformer(nn.Module): #!# todo : change transformer structure with user defined transformer structure\n",
    "    def __init__(self, d_model, nhead = 8, num_encoder_layers = 6, num_decoder_layers = 6, dim_feedforward = 2048):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.transformer = nn.Transformer( # https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html\n",
    "            d_model, \n",
    "            nhead = nhead, \n",
    "            num_encoder_layers = num_encoder_layers, \n",
    "            num_decoder_layers = num_decoder_layers, \n",
    "            dim_feedforward = dim_feedforward,\n",
    "            batch_first = True\n",
    "        ) \n",
    "        \n",
    "    def forward(self, f, q):\n",
    "        out = self.transformer(f, q)\n",
    "        return out\n",
    "\n",
    "class PredictionHead(nn.Module): #!# todo : try diff. prediction head\n",
    "    def __init__(self, d_model, num_class, num_class_layer = 10):\n",
    "        super(PredictionHead, self).__init__()\n",
    "        self.fc_layer_class = nn.ModuleList(\n",
    "            [nn.Linear(d_model, d_model) for _ in range(num_class_layer)]\n",
    "        )\n",
    "        \n",
    "        self.fc_layer_segment = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(d_model // 2, 2) # [x, y]\n",
    "        )\n",
    "        \n",
    "        self.activation = nn.GELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        c = x\n",
    "        for fc_layer in self.fc_layer_class:\n",
    "            c = fc_layer(c) + c\n",
    "            c = self.activation(c)\n",
    "            \n",
    "        b = self.fc_layer_segment(x)\n",
    "        return (c, b)\n",
    "    \n",
    "import math\n",
    "class PositionalEmbedding(nn.Module): #!# ref) https://github.com/codertimo/BERT-pytorch\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model, requires_grad = False).float()\n",
    "        pos = torch.arange(0, max_len).float()\n",
    "        div = (-(torch.arange(0, d_model, 2).float() / d_model) * math.log(10000.0)).exp()\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(torch.einsum('i,j->ij', pos, div))\n",
    "        pe[:, 1::2] = torch.cos(torch.einsum('i,j->ij', pos, div))\n",
    "        pe = rearrange(pe, 'i j -> () i j')\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting\n",
    "\n",
    "* build dataloader\n",
    "* model\n",
    "* loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "# fork ref) https://github.com/facebookresearch/detr/blob/091a817eca74b8b97e35e4531c1c39f89fbe38eb/models/detr.py#L83\n",
    "# code ref) https://www.kaggle.com/tanulsingh077/end-to-end-object-detection-with-transformers-detr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline 이 작동하는지 확인하기 위해 bert-base 활용\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/bigbird-roberta-base')\n",
    "lm = AutoModel.from_pretrained('google/bigbird-roberta-base') #!# 제출을 위해 local 에 다운받는 과정 필요.\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained('./model')\n",
    "# lm = AutoModel.from_pretrained('google/bigbird-roberta-base') #!# 제출을 위해 local 에 다운받는 과정 필요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!#\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "train_dataset_minibatch = dataset(train_df.iloc[:100], tokenizer, lm.config.max_position_embeddings, is_train = True)\n",
    "train_loader_minibatch = DataLoader(train_dataset_minibatch, batch_size = BATCH_SIZE, shuffle = True)\n",
    "\n",
    "train_dataset = dataset(train_df, tokenizer, lm.config.max_position_embeddings, is_train = True)\n",
    "train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''model parameter'''\n",
    "max_seq = lm.config.max_position_embeddings\n",
    "d_model = lm.config.hidden_size\n",
    "max_segment = 50\n",
    "num_class = len(output_labels_detr) - 1 # null-class\n",
    "\n",
    "device_0, device_1 = 1, 0\n",
    "\n",
    "FEATURE_EXTRACTOR = FeatureExtractor(lm).cuda(device_0)\n",
    "TRANSFORMER = Transformer(d_model).cuda(device_1)\n",
    "PREDICTION_HEAD = PredictionHead(d_model, num_class).cuda(device_1)\n",
    "PE = PositionalEmbedding(d_model, max_seq).cuda(device_1)\n",
    "DETR_HEAD = DetrHead(FEATURE_EXTRACTOR, TRANSFORMER, PREDICTION_HEAD, PE, max_seq, max_segment, d_model, device_0, device_1)\n",
    "\n",
    "model = DETR_HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''hyper parameter'''\n",
    "EPOCH = 1\n",
    "LR = 1e-5\n",
    "max_norm = 2 # gradient clipping\n",
    "\n",
    "weight_dict = {'weight_bbox' : 1, 'weight_class' : 0, 'weight_giou' : 1} #!# it is important to make sure the model learns bbox faster than class\n",
    "\n",
    "if_grad_clip = False\n",
    "if_scheduler = False\n",
    "\n",
    "class_loss = nn.CrossEntropyLoss()\n",
    "box_loss = nn.L1Loss()\n",
    "\n",
    "# 이하는 작업중인 hyper-parameters\n",
    "# null_class_coef = 0.5 #!# null class 학습이 전혀 안이뤄지는것도 문제가 있지... 지금은 전부 버리는데 이게 맞는 것 같지는 않아."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!# 여기부터 facebook source code 를 바꾸고 있음.\n",
    "#!# ref) https://github.com/facebookresearch/detr/blob/eb9f7e03ed8e2ed2cd55528989fe7df890bc3fc0/models/matcher.py#L12\n",
    "#!# 각 코드가 잘 작동하는지 *매우* 유의해서 살펴봐야 함.\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "#!# 높은 확률로 div zero 로 인한 overflow 예상됨. -> 아마 여기서 gradient exploding 문제가 발생했을듯\n",
    "#!# matching 이 초기에 이뤄지지 않으면 아예 학습이 안되는 알고리즘임에 주의하자. \n",
    "def one_dim_iou(out_bbox, tgt_bbox):\n",
    "    # assert (tgt_bbox[:, 1] >= tgt_bbox[:, 0]).all() #!# 이게 있어야 학습이 잘 이뤄질 것 같긴해... 근데 초기부터 이뤄지는게 가능한건가?\n",
    "    # assert (out_bbox[:, 1] >= out_bbox[:, 0]).all()\n",
    "    \n",
    "    max_matrix = torch.max(\n",
    "        repeat(out_bbox, 'bq i -> bq r i', r = tgt_bbox.size(0)), \n",
    "        repeat(tgt_bbox, 'bq i -> r bq i', r = out_bbox.size(0))\n",
    "    )\n",
    "\n",
    "    min_matrix = torch.min(\n",
    "        repeat(out_bbox, 'bq i -> bq r i', r = tgt_bbox.size(0)), \n",
    "        repeat(tgt_bbox, 'bq i -> r bq i', r = out_bbox.size(0))\n",
    "    )\n",
    "\n",
    "    return (min_matrix[:, :, 1] - max_matrix[:, :, 0]) / (max_matrix[:, :, 1] - min_matrix[:, :, 0])\n",
    "\n",
    "@torch.no_grad()\n",
    "def match(outputs : dict, targets : dict, weight_bbox = 1, weight_class = 1, weight_giou = 1):\n",
    "    '''scipy 의 linear_sum_assignment 를 활용해서 Hungarian matching 을 수행한다. \n",
    "    모델이 예측한 class 와 bounding box 를 토대로 target 과 비교해서\n",
    "    cost 를 최소화하는 matching 을 찾아낸다.\n",
    "    \n",
    "    #!# DETR 코드와 마찬가지로 target 에는 no-object class 가 없다. 즉, no-object 에 대해서는 loss 를 계산하지 않는다.\n",
    "    # ref) https://github.com/facebookresearch/detr/blob/eb9f7e03ed8e2ed2cd55528989fe7df890bc3fc0/models/matcher.py#L12\n",
    "    \n",
    "    Parameters\n",
    "        outputs: dict\n",
    "            - 'pred_logits': 각 class 에 대한 logit. 이후 softmax 를 통해 class 에 대한 확률 계산으로 사용된다.\n",
    "            - 'pred_boxes' :  예측한 bounding box. [x, y] 로 이뤄진다.\n",
    "        target: dict\n",
    "            - 'labels': 해당 segment 의 class\n",
    "            - 'boxes' : 해당 segment 의 bounding box [x, y]\n",
    "            \n",
    "    Returns\n",
    "        match_list: list [batch_size, [row_ind, col_ind]]\n",
    "            - 각 batch 에 대해서 row 와 col 의 matching index 정보를 담은 array 를 반환한다.\n",
    "    '''\n",
    "    \n",
    "    batch_size, num_query, num_tgt = outputs[\"pred_logits\"].size(0), outputs[\"pred_logits\"].size(1), targets['labels'].size(-1)\n",
    "\n",
    "    # We flatten to compute the cost matrices in a batch\n",
    "    out_prob = rearrange(outputs[\"pred_logits\"], 'b s c -> (b s) c').softmax(dim = -1)  # [batch_size * num_queries, num_classes]\n",
    "    out_bbox = rearrange(outputs[\"pred_boxes\"], 'b s box -> (b s) box')  # [batch_size * num_queries, 2]\n",
    "\n",
    "    # Also concat the target labels and boxes\n",
    "    tgt_ids  = torch.cat([v for v in targets[\"labels\"].type(torch.LongTensor)]).to(device)\n",
    "    tgt_bbox = torch.cat([v for v in targets[\"boxes\"]]).to(device)\n",
    "\n",
    "    # Compute the classification cost. Contrary to the loss, we don't use the NLL,\n",
    "    # but approximate it in 1 - proba[target class].\n",
    "    # The 1 is a constant that doesn't change the matching, it can be ommitted.\n",
    "    cost_class = -out_prob[:, tgt_ids]\n",
    "\n",
    "    # Compute the L1 cost between boxes\n",
    "    #!# 이거 normalize 안돼서 너무 클거임. 1/n_seq 해주는게 좋을 듯\n",
    "    cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1) # [batch_size * num_queries, batch_size * num_queries]\n",
    "\n",
    "    # Compute the giou cost betwen boxes\n",
    "    #!# 분명 overflow 문제 발생함.. 어떻게 해결할 수 있을까. detr 은 assert 사용함\n",
    "    cost_giou = -one_dim_iou(out_bbox, tgt_bbox)\n",
    "\n",
    "    #!# Final cost matrix\n",
    "    #!# need to change weight for loss\n",
    "    C = weight_bbox * cost_bbox + weight_class * cost_class + weight_giou * cost_giou\n",
    "    C = torch.nan_to_num(C, nan = 1e9) #!# linear_sum_assignment 는 nan 을 처리 못함.\n",
    "    C = rearrange(C, '(b1 q1) (b2 q2) -> b1 q1 b2 q2', # [batch_size, num_query, batch_size, num_query]\n",
    "                  b1 = batch_size, q1 = num_query, b2 = batch_size, q2 = num_tgt) \n",
    "\n",
    "    match_list = [linear_sum_assignment(C[b, :, b, :].detach().cpu()) for b in range(batch_size)]\n",
    "    return match_list\n",
    "\n",
    "@torch.no_grad()\n",
    "def _index_select_for_batch(x : torch.tensor, index : torch.tensor) -> torch.tensor:\n",
    "    '''Unfold batch and select element\n",
    "    Parameters\n",
    "        x : [batch, ..., index]\n",
    "        index : [batch, index]\n",
    "        \n",
    "    Returns\n",
    "        x (selected) : [batch, ..., index]\n",
    "    '''\n",
    "    x_shape = x.shape\n",
    "    \n",
    "    # unfold batch\n",
    "    index = torch.cat(tuple([torch.as_tensor(index_batch) + batch_idx * x_shape[1] for batch_idx, index_batch in enumerate(index)]), dim = 0) #\n",
    "    x = torch.cat(tuple([x_batch for x_batch in x]), dim = 0)\n",
    "    x = torch.index_select(x, 0, index)\n",
    "    \n",
    "    return x.view(x_shape)\n",
    "\n",
    "def _unfold_batch(x): # batch_first = True\n",
    "    return torch.cat(tuple([x_batch for x_batch in x]), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DETR_HEAD\n",
    "\n",
    "loss_traj = []\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer=optimizer,\n",
    "    lr_lambda=lambda i: 0.95 ** i,\n",
    "    last_epoch=-1,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for _ in range(1):\n",
    "    for batch in tqdm(train_loader_minibatch): #!# train_loader\n",
    "        text_id_list = batch.pop('id')\n",
    "        batch = {k : v.cuda(device_0) for k, v in batch.items()}\n",
    "\n",
    "        c, b = model(batch) # c : class, b : bounding box\n",
    "        out = {'pred_logits' : c, 'pred_boxes' : b}\n",
    "        tgt = {'labels' : batch['labels'][:, :, 0], 'boxes' : batch['labels'][:, :, 1:] / max_seq} #!# input normalization\n",
    "\n",
    "        match_list = match(out, tgt, **weight_dict)\n",
    "        match_list = [list(index_batch[1]) for index_batch in match_list]\n",
    "        \n",
    "        loss = \\\n",
    "            0 * class_loss( #!# learn only segmentation\n",
    "                _unfold_batch(out['pred_logits'].softmax(dim = -1)).cuda(device_1),\n",
    "                _unfold_batch(_index_select_for_batch(tgt['labels'].type(torch.LongTensor), match_list).cuda(device_1))\n",
    "            ) + \\\n",
    "            weight_dict['weight_bbox'] * box_loss(\n",
    "                _unfold_batch(out['pred_boxes']).cuda(device_1),\n",
    "                _unfold_batch(_index_select_for_batch(tgt['boxes'].type(torch.LongTensor), match_list).cuda(device_1))\n",
    "            )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        if if_grad_clip:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if if_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        loss_traj.append(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.feature_extractor.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR)\n",
    "\n",
    "for _ in range(1):\n",
    "    for batch in tqdm(train_loader_minibatch): #!# train_loader\n",
    "        text_id_list = batch.pop('id')\n",
    "        batch = {k : v.cuda(device_0) for k, v in batch.items()}\n",
    "\n",
    "        c, b = model(batch) # c : class, b : bounding box\n",
    "        out = {'pred_logits' : c, 'pred_boxes' : b}\n",
    "        tgt = {'labels' : batch['labels'][:, :, 0], 'boxes' : batch['labels'][:, :, 1:] / max_seq} #!# input normalization\n",
    "\n",
    "        match_list = match(out, tgt, **weight_dict)\n",
    "        match_list = [list(index_batch[1]) for index_batch in match_list]\n",
    "        \n",
    "        loss = \\\n",
    "            1 * class_loss( #!# learn classification module\n",
    "                _unfold_batch(out['pred_logits'].softmax(dim = -1)).cuda(device_1),\n",
    "                _unfold_batch(_index_select_for_batch(tgt['labels'].type(torch.LongTensor), match_list).cuda(device_1))\n",
    "            ) + \\\n",
    "            weight_dict['weight_bbox'] * box_loss(\n",
    "                _unfold_batch(out['pred_boxes']).cuda(device_1),\n",
    "                _unfold_batch(_index_select_for_batch(tgt['boxes'].type(torch.LongTensor), match_list).cuda(device_1))\n",
    "            )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        if if_grad_clip:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if if_scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "        loss_traj.append(float(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!# why classification mal-functioning?\n",
    "# 1. positional encoding (query, feature)\n",
    "# 2. fc_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "         6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "         6, 6]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['pred_logits'].argmax(dim = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 : matching function\n",
    "# 2 : loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE, num_class, max_segment = 2, 7, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_tgt = torch.cat((torch.randint(1, num_class+1, (BATCH_SIZE, max_segment, 1)), torch.rand(BATCH_SIZE, max_segment, 2)), dim = -1) # [class, x, y]\n",
    "ex_indices = torch.stack([torch.randperm(max_segment) for _ in range(BATCH_SIZE)], dim = 0)\n",
    "ex_out_true = _index_select_for_batch(ex_tgt, ex_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_out_dict = lambda x : {'pred_logits' : 0.9 * F.one_hot(x[:, :, 0].type(torch.LongTensor), num_classes = num_class+1), 'pred_boxes' : x[:, :, 1:]}\n",
    "convert_tgt_dict = lambda x : {'labels' : x[:, :, 0], 'boxes' : x[:, :, 1:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 3])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_out_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_out_true_dict = convert_out_dict(ex_out_true)\n",
    "ex_tgt_dict = convert_tgt_dict(ex_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0, 1, 2, 3, 4]), array([0, 4, 2, 1, 3], dtype=int64)),\n",
       " (array([0, 1, 2, 3, 4]), array([0, 1, 4, 3, 2], dtype=int64))]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match(ex_out_true_dict, ex_tgt_dict) # some times... match failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True],\n",
       "        [ True, False, False, False, False]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_indices == torch.as_tensor([list(tgt_idx) for out_idx, tgt_idx in match(ex_out_true_dict, ex_tgt_dict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 4, 2, 1, 3],\n",
       "        [2, 0, 1, 3, 4]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out['predict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 2., 7., 6., 7.],\n",
       "        [7., 7., 7., 6., 2.]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 7, 7, 2, 6],\n",
       "        [7, 7, 7, 6, 2]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_index_select_for_batch(tgt['labels'].type(torch.LongTensor), match_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7., 2., 7., 6., 7.],\n",
       "        [7., 7., 7., 6., 2.]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7, 2, 7, 6, 7],\n",
       "        [7, 7, 7, 6, 2]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgt['labels'].type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 4, 2, 1, 3],\n",
       "        [2, 0, 1, 3, 4]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ex_out_true_dict\n",
    "tgt = ex_tgt_dict\n",
    "match_list = torch.as_tensor([list(tgt_idx) for out_idx, tgt_idx in match(ex_out_true_dict, ex_tgt_dict)])\n",
    "\n",
    "loss = \\\n",
    "    class_loss(\n",
    "        _unfold_batch(out['pred_logits'].softmax(dim = -1)),\n",
    "        _unfold_batch(_index_select_for_batch(tgt['labels'].type(torch.LongTensor), match_list))\n",
    "    ) + \\\n",
    "    box_loss(\n",
    "        _unfold_batch(out['pred_boxes'].softmax(dim = -1)),\n",
    "        _unfold_batch(_index_select_for_batch(tgt['boxes'].type(torch.LongTensor), match_list))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = ex_out_true_dict\n",
    "targets = ex_tgt_dict\n",
    "batch_size, num_query, num_tgt = outputs[\"pred_logits\"].size(0), outputs[\"pred_logits\"].size(1), targets['labels'].size(-1)\n",
    "\n",
    "# We flatten to compute the cost matrices in a batch\n",
    "out_prob = rearrange(outputs[\"pred_logits\"], 'b s c -> (b s) c').softmax(dim = -1)  # [batch_size * num_queries, num_classes]\n",
    "out_bbox = rearrange(outputs[\"pred_boxes\"], 'b s box -> (b s) box')  # [batch_size * num_queries, 2]\n",
    "\n",
    "# Also concat the target labels and boxes\n",
    "tgt_ids  = torch.cat([v for v in targets[\"labels\"].type(torch.LongTensor)]).to(device)\n",
    "tgt_bbox = torch.cat([v for v in targets[\"boxes\"]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "# Compute the classification cost. Contrary to the loss, we don't use the NLL,\n",
    "# but approximate it in 1 - proba[target class].\n",
    "# The 1 is a constant that doesn't change the matching, it can be ommitted.\n",
    "cost_class = -out_prob[:, tgt_ids]\n",
    "print(cost_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = ex_indices.size(0)\n",
    "index = torch.cat(tuple([index_batch + batch_idx * batch_size for batch_idx, index_batch in enumerate(ex_indices)]), dim = 0) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 2, 4, 0, 4, 2, 6, 5, 3])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 1, 2, 4, 0],\n",
       "        [2, 0, 4, 3, 1]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_indices = torch.cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "# Compute the L1 cost between boxes\n",
    "#!# 이거 normalize 안돼서 너무 클거임. 1/n_seq 해주는게 좋을 듯\n",
    "cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1) # [batch_size * num_queries, batch_size * num_queries]\n",
    "print(cost_bbox.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "# Compute the giou cost betwen boxes\n",
    "#!# 분명 overflow 문제 발생함.. 어떻게 해결할 수 있을까. detr 은 assert 사용함\n",
    "cost_giou = -one_dim_iou(out_bbox, tgt_bbox)\n",
    "print(cost_giou.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!# Final cost matrix\n",
    "#!# need to change weight for loss\n",
    "C = weight_bbox * cost_bbox + weight_class * cost_class + weight_giou * cost_giou\n",
    "C = torch.nan_to_num(C, nan = 1e9) #!# linear_sum_assignment 는 nan 을 처리 못함.\n",
    "C = rearrange(C, '(b1 q1) (b2 q2) -> b1 q1 b2 q2', # [batch_size, num_query, batch_size, num_query]\n",
    "              b1 = batch_size, q1 = num_query, b2 = batch_size, q2 = num_tgt) \n",
    "\n",
    "match_list = [linear_sum_assignment(C[b, :, b, :].detach().cpu()) for b in range(batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_indices = match(ex_out_true_dict, ex_tgt_dict) #!# awkard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_indices = torch.as_tensor([list(tgt_idx) for out_idx, tgt_idx in match_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_tgt_matched = _index_select_for_batch(ex_tgt, match_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.0000, 0.5725, 0.4980],\n",
       "         [4.0000, 0.6826, 0.3051],\n",
       "         [5.0000, 0.4635, 0.4550],\n",
       "         [4.0000, 0.9371, 0.6556],\n",
       "         [1.0000, 0.6387, 0.5247]],\n",
       "\n",
       "        [[4.0000, 0.9371, 0.6556],\n",
       "         [5.0000, 0.4635, 0.4550],\n",
       "         [1.0000, 0.4162, 0.2843],\n",
       "         [7.0000, 0.3138, 0.1980],\n",
       "         [4.0000, 0.5725, 0.4980]]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_out_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.6387, 0.5247],\n",
       "         [5.0000, 0.4635, 0.4550],\n",
       "         [4.0000, 0.6826, 0.3051],\n",
       "         [4.0000, 0.9371, 0.6556],\n",
       "         [4.0000, 0.5725, 0.4980]],\n",
       "\n",
       "        [[7.0000, 0.3138, 0.1980],\n",
       "         [4.0000, 0.9371, 0.6556],\n",
       "         [5.0000, 0.4635, 0.4550],\n",
       "         [4.0000, 0.5725, 0.4980],\n",
       "         [1.0000, 0.4162, 0.2843]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_tgt_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_tgt_dict = {'labels' : out_true[:, :, 0], 'boxes' : out_true[:, :, 1:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 'pred_logits': 각 class 에 대한 logit. 이후 softmax 를 통해 class 에 대한 확률 계산으로 사용된다.\n",
    "            - 'pred_boxes' :  예측한 bounding box. [x, y] 로 이뤄진다.\n",
    "        target: dict\n",
    "            - 'labels': 해당 segment 의 class\n",
    "            - 'boxes' : 해당 segment 의 bounding box [x, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 3])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_tgt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-d022bffc8354>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mex_out_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex_tgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "ex_out_true = torch.index_select(ex_tgt, 0, true_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. with true output, can matcher find true indices?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = DETR_HEAD.to(device)\n",
    "loss_traj = []\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optimizer=optimizer,\n",
    "    lr_lambda=lambda i: 0.95 ** i,\n",
    "    last_epoch=-1,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "model.train()\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "for i, batch in enumerate(train_loader_minibatch):\n",
    "    batch = {k : v.to(device) for k, v in batch.items()}\n",
    "    break\n",
    "    \n",
    "class_pred, box_pred = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_pred.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2528],\n",
       "         [261.0119, 253.2528],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2528],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2530],\n",
       "         [261.0119, 253.2528],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0120, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2528],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529]],\n",
       "\n",
       "        [[261.0118, 253.2530],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2528],\n",
       "         [261.0118, 253.2528],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2528],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2528],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0119, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529],\n",
       "         [261.0118, 253.2529]]], device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq * (0.5 - box_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = {'id' : [], 'class' : [], 'predictionstring' : []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(' '))\n",
    "    set_gt = set(row.predictionstring_gt.split(' '))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter/ len_pred\n",
    "    return [overlap_1, overlap_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pred, b = model(batch)\n",
    "c_pred = torch.argmax(c_pred, dim = -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "= max_seq * (0.5 - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(batch):\n",
    "    # MOVE BATCH TO GPU AND INFER\n",
    "    ids = batch[\"input_ids\"].to(config['device'])\n",
    "    mask = batch[\"attention_mask\"].to(config['device'])\n",
    "    outputs = model(ids, attention_mask=mask, return_dict=False)\n",
    "    all_preds = torch.argmax(outputs[0], axis=-1).cpu().numpy() \n",
    "\n",
    "    # INTERATE THROUGH EACH TEXT AND GET PRED\n",
    "    predictions = []\n",
    "    for k,text_preds in enumerate(all_preds):\n",
    "        token_preds = [ids_to_labels[i] for i in text_preds]\n",
    "\n",
    "        prediction = []\n",
    "        word_ids = batch['wids'][k].numpy()  \n",
    "        previous_word_idx = -1\n",
    "        for idx,word_idx in enumerate(word_ids):                            \n",
    "            if word_idx == -1:\n",
    "                pass\n",
    "            elif word_idx != previous_word_idx:              \n",
    "                prediction.append(token_preds[idx])\n",
    "                previous_word_idx = word_idx\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/zzy990106/pytorch-ner-infer\n",
    "# changed a little bit (용현)\n",
    "\n",
    "df=valid_dataset\n",
    "loader=valid_loader\n",
    "\n",
    "# put model in eval mode\n",
    "model.eval()\n",
    "\n",
    "# calc prediction from model\n",
    "model_predict = []\n",
    "for batch in loader:\n",
    "    labels = inference(batch)\n",
    "    y_pred2.extend(labels)\n",
    "\n",
    "final_preds2 = []\n",
    "for i in range(len(df)):\n",
    "\n",
    "    idx = df.id.values[i]\n",
    "    #pred = [x.replace('B-','').replace('I-','') for x in y_pred2[i]]\n",
    "    pred = y_pred2[i] # Leave \"B\" and \"I\"\n",
    "    preds = []\n",
    "    j = 0\n",
    "    while j < len(pred):\n",
    "        cls = pred[j]\n",
    "        if cls == 'O': j += 1\n",
    "        else: cls = cls.replace('B','I') # spans start with B\n",
    "        end = j + 1\n",
    "        while end < len(pred) and pred[end] == cls:\n",
    "            end += 1\n",
    "\n",
    "        if cls != 'O' and cls != '' and end - j > 7:\n",
    "            final_preds2.append((idx, cls.replace('I-',''),\n",
    "                                 ' '.join(map(str, list(range(j, end))))))\n",
    "\n",
    "        j = end\n",
    "\n",
    "oof = pd.DataFrame(final_preds2)\n",
    "oof.columns = ['id','class','predictionstring']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "        \n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df[['id','discourse_type','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df = pred_df[['id','class','predictionstring']] \\\n",
    "        .reset_index(drop=True).copy()\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(gt_df,\n",
    "                           left_on=['id','class'],\n",
    "                           right_on=['id','discourse_type'],\n",
    "                           how='outer',\n",
    "                           suffixes=('_pred','_gt')\n",
    "                          )\n",
    "    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n",
    "    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n",
    "\n",
    "    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5, \n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n",
    "    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "\n",
    "    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n",
    "    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n",
    "    tp_pred_ids = joined.query('potential_TP') \\\n",
    "        .sort_values('max_overlap', ascending=False) \\\n",
    "        .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n",
    "    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    #calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5*(FP+FN))\n",
    "    return my_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VALID TARGETS\n",
    "valid = train_df.loc[train_df['id'].isin(IDS[valid_idx])]\n",
    "\n",
    "# OOF PREDICTIONS\n",
    "oof = get_predictions(test_dataset, testing_loader)\n",
    "\n",
    "# COMPUTE F1 SCORE\n",
    "f1s = []\n",
    "CLASSES = oof['class'].unique()\n",
    "print()\n",
    "for c in CLASSES:\n",
    "    pred_df = oof.loc[oof['class']==c].copy()\n",
    "    gt_df = valid.loc[valid['discourse_type']==c].copy()\n",
    "    f1 = score_feedback_comp(pred_df, gt_df)\n",
    "    print(c,f1)\n",
    "    f1s.append(f1)\n",
    "print()\n",
    "print('Overall',np.mean(f1s))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for submission\n",
    "# ref) https://www.kaggle.com/cdeotte/pytorch-bigbird-ner-cv-0-615?scriptVersionId=83230719\n",
    "test_names, test_texts = [], []\n",
    "for f in list(os.listdir('../input/feedback-prize-2021/test')):\n",
    "    test_names.append(f.replace('.txt', ''))\n",
    "    test_texts.append(open('../input/feedback-prize-2021/test/' + f, 'r').read())\n",
    "test_texts = pd.DataFrame({'id': test_names, 'text': test_texts})\n",
    "\n",
    "test_names, train_texts = [], []\n",
    "for f in tqdm(list(os.listdir('../input/feedback-prize-2021/train'))):\n",
    "    test_names.append(f.replace('.txt', ''))\n",
    "    train_texts.append(open('../input/feedback-prize-2021/train/' + f, 'r').read())\n",
    "train_text_df = pd.DataFrame({'id': test_names, 'text': train_texts})\n",
    "\n",
    "\n",
    "# # TEST DATASET\n",
    "# test_texts_set = dataset(test_texts, tokenizer, config['max_length'], True)\n",
    "# test_texts_loader = DataLoader(test_texts_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define config\n",
    "config = {'model_name': MODEL_NAME,   \n",
    "          'max_length': 1024,\n",
    "          'train_batch_size':4,\n",
    "          'valid_batch_size':4,\n",
    "          'epochs':5,\n",
    "          'learning_rates': [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7],\n",
    "          'max_grad_norm':10,\n",
    "          'device': 'cuda' if cuda.is_available() else 'cpu'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666cc845bdc54244acb9aff81cef5626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51674fa78df049babf1e80f7e1b66fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e6301eb1b248a7aa55f1f9062defcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/846k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055c9165c0c64092805d94e89973a1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/775 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9508107e9dd543fa9c6ed48270f8d929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/513M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/bigbird-roberta-base were not used when initializing BigBirdForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BigBirdForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BigBirdForTokenClassification were not initialized from the model checkpoint at google/bigbird-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# if you are first running this code, please download LM.\n",
    "MODEL_NAME = 'google/bigbird-roberta-base' # choose which model to download\n",
    "DOWNLOADED_MODEL_PATH = 'model'            # choose where to download the model\n",
    "\n",
    "if DOWNLOADED_MODEL_PATH == 'model':\n",
    "    os.mkdir('model')\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, add_prefix_space=True) #!# add_prefix_space?\n",
    "    tokenizer.save_pretrained('model')\n",
    "\n",
    "    config_model = AutoConfig.from_pretrained(MODEL_NAME) \n",
    "    config_model.num_labels = 15\n",
    "    config_model.save_pretrained('model')\n",
    "\n",
    "    backbone = AutoModelForTokenClassification.from_pretrained(MODEL_NAME, \n",
    "                                                               config=config_model)\n",
    "    backbone.save_pretrained('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!# implement tokenizer \\n\\n, to see paragraph information\n",
    "# ref) https://github.com/huggingface/tokenizers/issues/247\n",
    "# ref) https://www.kaggle.com/c/feedback-prize-2021/discussion/296713\n",
    "tokenizer.decode(tokenizer(r'\\\\n\\\\n', return_offsets_mapping=True)['input_ids'])\n",
    "\n",
    "'''add new special token to model and tokenizer'''\n",
    "special_tokens_dict = {'additional_special_tokens': [r'\\\\n\\\\n']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i) \n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:                \n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            else:  \n",
    "                label_ids.append(label[word_idx])\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snu36",
   "language": "python",
   "name": "snu36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
