{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33menkeejunior1\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/enkeejunior1/fbprize/runs/217uq2vd\" target=\"_blank\">pleasant-lion-72</a></strong> to <a href=\"https://wandb.ai/enkeejunior1/fbprize\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from train_yh import *\n",
    "from utils_yh import *\n",
    "from preprocess import *\n",
    "from model_yh import *\n",
    "from data import *\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import warnings\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from einops import rearrange, reduce, repeat\n",
    "import tez\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n",
    "\n",
    "import copy\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import AdamW, AutoConfig, AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n",
    "from joblib import Parallel, delayed \n",
    "from tez import enums\n",
    "from tez.callbacks import Callback\n",
    "from tqdm import tqdm\n",
    "\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:217uq2vd) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 21205... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42921b9ac8a845419f8eb7056fcb12ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">pleasant-lion-72</strong>: <a href=\"https://wandb.ai/enkeejunior1/fbprize/runs/217uq2vd\" target=\"_blank\">https://wandb.ai/enkeejunior1/fbprize/runs/217uq2vd</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220222_113608-217uq2vd/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:217uq2vd). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to `offline` in this directory.  <br/>\n",
       "Run `wandb online` or set WANDB_MODE=online to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f93e83d4908>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/home/enkeejunior1/kaggle_feedbackprize/fb-sbert-yh')\n",
    "wandb.init(mode=\"offline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "class set_args_submission:\n",
    "    def __init__(self):\n",
    "        self.model: str = 'longformer-large-4096'\n",
    "        self.sbert: bool = False\n",
    "        self.output: str = '../submission_model'\n",
    "        self.input: str = '../input'\n",
    "        self.max_len: int = 4096 # need to debug\n",
    "        self.valid_batch_size: int = 4\n",
    "        self.kfold = 5\n",
    "        self.fold = 0\n",
    "            \n",
    "args = set_args_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read kfold data\n",
    "if os.path.isfile(args.input + '/' + f'train_{args.kfold}folds.csv'):\n",
    "    df = pd.read_csv(args.input + '/' + f'train_{args.kfold}folds.csv')\n",
    "else:\n",
    "    df = pd.read_csv(args.input_path + '/' + f'train.csv')\n",
    "    df = get_stratified_fold(df, args)\n",
    "\n",
    "train_df = df[df[f\"{args.kfold}fold\"] != args.fold].reset_index(drop=True)\n",
    "valid_df = df[df[f\"{args.kfold}fold\"] == args.fold].reset_index(drop=True)\n",
    "\n",
    "args_path = os.listdir(args.output)\n",
    "args_path = list(filter(lambda x: '.json' in x, args_path))\n",
    "\n",
    "args_dict_list = []\n",
    "for path in args_path:\n",
    "    with open(os.path.join(args.output, path), 'r') as fp:\n",
    "        args_model = json.load(fp)\n",
    "    args_dict_list.append(args_model)\n",
    "    \n",
    "class ArgsModelCheck:\n",
    "    @classmethod\n",
    "    def __init__(cls, args_dict):\n",
    "        for k, v in args_dict.items():\n",
    "            setattr(cls, k, v)\n",
    "\n",
    "args_list = []\n",
    "for i, args_dict in enumerate(args_dict_list):\n",
    "    fold = args_dict['fold']\n",
    "    cv_score = args_dict['cv_score']\n",
    "    globals()[f'args_{i}'] = ArgsModelCheck(args_dict)\n",
    "    args_list.append(globals()[f'args_{i}'])\n",
    "    \n",
    "# 모델 불러오기\n",
    "model_list = []\n",
    "for i, args_model in enumerate(args_list):\n",
    "    globals()[f'model_{i}'] = BestModel(\n",
    "            model_name=args.model,\n",
    "            num_train_steps=0,\n",
    "            learning_rate=0,\n",
    "            num_labels=len(target_id_map) - 1,\n",
    "            steps_per_epoch=0,\n",
    "            args=args,\n",
    "            device='cpu',\n",
    "        )\n",
    "    weight_path = os.path.join(args.output, f'{args_model.model}-{args_model.time}.bin')\n",
    "    globals()[f'model_{i}'].load_state_dict(torch.load(weight_path))\n",
    "    globals()[f'model_{i}'].eval()\n",
    "    model_list.append(globals()[f'model_{i}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = args_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args_dict = vars(args)\n",
    "# for args_model_dict in args_dict_list:\n",
    "#     for k, v in args_model_dict.items():\n",
    "#         if k not in args_dict.keys():\n",
    "#             setattr(args, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4105 > 4096). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(args.model)\n",
    "\n",
    "args.sbert = True #!# 이게 왜 안먹지..?\n",
    "train_samples = prepare_training_data(valid_df, tokenizer, args = args, num_jobs = 12)\n",
    "collate = TrainCollate(tokenizer, args)\n",
    "train_dataset = FeedbackDataset(train_samples, args.max_len, tokenizer, args = args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=8, \n",
    "    num_workers=1,\n",
    "    collate_fn=collate, \n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 가 높게 나오는 sample 살펴보기\n",
    "# sentence 구분이랑 target 이랑 얼마나 일치하는지 확인하기\n",
    "# 실제 prediction 살펴보고, 잘 못하는 sample 확인하기 (아직 token level 에서만 확인)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-Lead': 0,\n",
       " 'I-Lead': 1,\n",
       " 'B-Position': 2,\n",
       " 'I-Position': 3,\n",
       " 'B-Evidence': 4,\n",
       " 'I-Evidence': 5,\n",
       " 'B-Claim': 6,\n",
       " 'I-Claim': 7,\n",
       " 'B-Concluding Statement': 8,\n",
       " 'I-Concluding Statement': 9,\n",
       " 'B-Counterclaim': 10,\n",
       " 'I-Counterclaim': 11,\n",
       " 'B-Rebuttal': 12,\n",
       " 'I-Rebuttal': 13,\n",
       " 'O': 14,\n",
       " 'PAD': -100}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in data_loader:\n",
    "    with torch.no_grad():\n",
    "        model = model_list[0]\n",
    "        model.eval()\n",
    "        a = model(**batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:37, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def _extract_output(output, target, attention_mask, sentence_mask = None):\n",
    "    '''attention mask == 1 인 부분만 추출\n",
    "    Parameters\n",
    "        - output: torch.tensor = [batch_size, seq_len, num_class]\n",
    "        - attention_mask:   torch.tensor = [batch_size, seq_len]\n",
    "    '''\n",
    "    output = [o for o in output]\n",
    "    target = [t for t in target]\n",
    "    attention_mask = [m for m in attention_mask]\n",
    "    \n",
    "    output_list = []\n",
    "    target_list = []\n",
    "    sent_list = []\n",
    "    if sentence_mask is None:\n",
    "        for o, t, m in zip(output, target, attention_mask):\n",
    "            output_list.append(o[m == 1].cpu())\n",
    "            target_list.append(t[m == 1].cpu())\n",
    "        return output_list, target_list\n",
    "    else:\n",
    "        for o, t, s, m in zip(output, target, sentence_mask, attention_mask):\n",
    "            output_list.append(o[m == 1].cpu())\n",
    "            target_list.append(t[m == 1].cpu())\n",
    "            sent_list.append(s[m == 1].cpu())\n",
    "        return output_list, target_list, sent_list\n",
    "        \n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(data_loader, model):\n",
    "    global device, args\n",
    "    for _, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            data['ids'] = data['ids'].to(device)\n",
    "            data['mask'] = data['mask'].to(device)\n",
    "            if args.sbert:\n",
    "                sent_mask = [s for s in data['input_type_list']]\n",
    "            output, loss, metric = model(**data)\n",
    "            output, target, sent_mask = _extract_output(output, data['targets'], data['mask'])\n",
    "            yield {\n",
    "                'output' : output,\n",
    "                'target' : target,\n",
    "                'sent_mask' : sent_mask,\n",
    "                'loss' : [loss],\n",
    "                'f1' : [metric['f1']],\n",
    "            }\n",
    "\n",
    "preds_iter_list = []\n",
    "for model in model_list:\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    preds_iter = predict(data_loader, model)\n",
    "    preds_iter_list.append(preds_iter)\n",
    "\n",
    "raw_model_output_list = []\n",
    "for preds_iter in preds_iter_list:\n",
    "    raw_model_output = {\n",
    "        'output' : [],\n",
    "        'target' : [],\n",
    "        'sent_mask' : [],\n",
    "        'loss' : [],\n",
    "        'f1' : [],\n",
    "    }\n",
    "    current_idx = 0\n",
    "    for preds in tqdm(preds_iter):\n",
    "        for k, v in preds.items():\n",
    "            raw_model_output[k].extend(v)\n",
    "        current_idx += 1\n",
    "        break\n",
    "    raw_model_output_list.append(raw_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['output', 'target', 'sent_mask', 'loss', 'f1'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_model_output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = raw_model_output['output'][0].argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_model_output['target'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_mask = [mask[0:267] for mask in raw_model_output['sent_mask'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14, 14, 14, 14, 14, 14, 14,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  5, 14, 14,  4,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5, 14, 14,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5, 14, 14,  8,  9,\n",
       "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14, 14, 14, 14, 14, 14, 14,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7, 14, 14,  4,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5, 14, 14,  8,  9,\n",
       "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_model_output['target'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_class == raw_model_output['target'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14, 14, 14, 14, 14, 14, 14,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7, 14, 14,  4,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5, 14, 14,  8,  9,\n",
       "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_model_output['target'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"raw_preds_list\", \"wb\") as fp:\n",
    "    pickle.dump(raw_preds_list, fp)\n",
    "    \n",
    "with open(\"raw_tgts_list\", \"wb\") as fp:\n",
    "    pickle.dump(raw_tgts_list, fp)\n",
    "\n",
    "with open(\"raw_sent_list\", \"wb\") as fp:\n",
    "    pickle.dump(raw_sent_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"raw_preds_list\", \"wb\") as fp:\n",
    "    raw_preds_list = pickle.load(fp)\n",
    "    \n",
    "with open(\"raw_tgts_list\", \"wb\") as fp:\n",
    "    raw_tgts_list = pickle.load(fp)\n",
    "\n",
    "with open(\"raw_sent_list\", \"wb\") as fp:\n",
    "    raw_sent_list = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_preds_list[0][0].argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 14, 14, 14, 14,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5, 14, 14,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5, 14, 14,  6,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  4,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5, 14, 14,  4,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5, 14, 14,  6,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  4,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  8,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "       14, 14, 14, 14, 14])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_tgts_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "final_scores = []\n",
    "\n",
    "for rp in raw_preds:\n",
    "    pred_class = np.argmax(rp, axis=2)\n",
    "    pred_scrs = np.max(rp, axis=2)\n",
    "    for pred, pred_scr in zip(pred_class, pred_scrs):\n",
    "        pred = pred.tolist()\n",
    "        pred_scr = pred_scr.tolist()\n",
    "        final_preds.append(pred)\n",
    "        final_scores.append(pred_scr)\n",
    "\n",
    "for j in range(len(test_samples)):\n",
    "    tt = [id_target_map[p] for p in final_preds[j][1:]]\n",
    "    tt_score = final_scores[j][1:]\n",
    "    test_samples[j][\"preds\"] = tt\n",
    "    test_samples[j][\"pred_scores\"] = tt_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create examplar input\n",
    "num_ex = 100 # number of text\n",
    "num_seq = 100\n",
    "num_ensemble = 10\n",
    "num_class = len(target_id_map)\n",
    "\n",
    "pred_iter_ex = [torch.rand(num_class, num_ensemble).softmax(dim = -1).view(-1).tolist() for _ in range(num_seq * num_ex)] # [num_class * num_ensemble, num_seq * num_ex]\n",
    "true_token_class = torch.randint(0, num_class + 1, (num_seq, num_ex)).view(-1).tolist() # [num_seq * num_ex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44min 26s, sys: 2.93 s, total: 44min 29s\n",
      "Wall time: 9min 34s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             gamma=0, gpu_id=-1, importance_type=None,\n",
       "             interaction_constraints='', learning_rate=0.300000012,\n",
       "             max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "             monotone_constraints='()', n_estimators=100, n_jobs=40,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "my_model = XGBRegressor(tree_method = \"gpu_hist\")\n",
    "my_model.fit(pred_iter_ex, true_token_class, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_iter = [torch.rand(num_class, num_ensemble).softmax(dim = -1) for range(num_seq)]\n",
    "true_token_class = torch.randint(0, num_class + 1, (num_seq, num_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_path = os.listdir('../model')\n",
    "args_path = list(filter(lambda x: '.json' in x, args_path))\n",
    "\n",
    "args_dict_list = []\n",
    "for path in args_path:\n",
    "    with open(os.path.join('../model', path), 'r') as fp:\n",
    "        args = json.load(fp)\n",
    "    args_dict_list.append(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArgsModelCheck:\n",
    "    @classmethod\n",
    "    def __init__(cls, args_dict):\n",
    "        for k, v in args_dict.items():\n",
    "            setattr(cls, k, v)\n",
    "\n",
    "args_list = []\n",
    "for i, args_dict in enumerate(args_dict_list):\n",
    "    fold = args_dict['fold']\n",
    "    cv_score = args_dict['cv_score']\n",
    "    globals()[f'args_{i}'] = ArgsModelCheck(args_dict)\n",
    "    args_list.append(globals()[f'args_{i}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out of fold ensemble -> cv check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (6229 > 4096). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7614 > 4096). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8580 > 4096). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (8862 > 4096). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (14778 > 4096). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "model = FeedbackModel(\n",
    "            model_name=args.model,\n",
    "            num_train_steps=0,\n",
    "            learning_rate=0,\n",
    "            num_labels=len(target_id_map) - 1,\n",
    "            steps_per_epoch=0,\n",
    "            args=args,\n",
    "        )\n",
    "\n",
    "weight_path = os.path.join(args.output, f'{args.model}-{args.time}.bin')\n",
    "model.load_state_dict(torch.load(weight_path))\n",
    "model.eval()\n",
    "\n",
    "# 데이터 불러오기\n",
    "df = pd.read_csv(args.input + '/' + f'train_{args.kfold}folds.csv')\n",
    "df_ids = df[\"id\"].unique()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model)\n",
    "training_samples = prepare_training_data(df, tokenizer, args, num_jobs=12)\n",
    "collate = TrainCollate(tokenizer, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = FeedbackDataset(training_samples, args.max_len, tokenizer, args = args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3899 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (0) must match the size of tensor b (4) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-27a720c2106c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mcurrent_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mraw_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-27a720c2106c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(data_loader, model)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_type_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_type_list'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle_feedbackprize/fb-sbert-yh/train_yh.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, mask, input_type_list, token_type_ids, targets)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msbert_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msbert_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msbert_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (0) must match the size of tensor b (4) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "n_jobs = psutil.cpu_count()\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    training_dataset, \n",
    "    batch_size=args.batch_size, \n",
    "    num_workers=n_jobs,  \n",
    "    collate_fn=collate, \n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "def predict(data_loader, model):\n",
    "    global device\n",
    "    tk0 = tqdm(data_loader, total = len(data_loader))\n",
    "    for _, data in enumerate(tk0):\n",
    "        with torch.no_grad():\n",
    "            data['ids'] = data['ids'].to(device)\n",
    "            data['mask'] = data['mask'].to(device)\n",
    "            data['input_type_list'] = [s.to(device) for s in data['input_type_list']]\n",
    "\n",
    "            output, _, _ = model(**data)\n",
    "            output = output.cpu().detach().numpy()\n",
    "            yield output\n",
    "    tk0.close()\n",
    "\n",
    "model.to(device)\n",
    "preds_iter = predict(data_loader, model)\n",
    "\n",
    "raw_preds = []\n",
    "current_idx = 0\n",
    "\n",
    "for preds in preds_iter:\n",
    "    preds = preds.astype(np.float16)\n",
    "    raw_preds.append(preds)\n",
    "    current_idx += 1\n",
    "    \n",
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "final_scores = []\n",
    "\n",
    "for rp in raw_preds:\n",
    "    pred_class = np.argmax(rp, axis=2)\n",
    "    pred_scrs = np.max(rp, axis=2)\n",
    "    for pred, pred_scr in zip(pred_class, pred_scrs):\n",
    "        pred = pred.tolist()\n",
    "        pred_scr = pred_scr.tolist()\n",
    "        final_preds.append(pred)\n",
    "        final_scores.append(pred_scr)\n",
    "\n",
    "for j in range(len(test_samples)):\n",
    "    tt = [id_target_map[p] for p in final_preds[j][1:]]\n",
    "    tt_score = final_scores[j][1:]\n",
    "    test_samples[j][\"preds\"] = tt\n",
    "    test_samples[j][\"pred_scores\"] = tt_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jn(pst, start, end):\n",
    "    return \" \".join([str(x) for x in pst[start:end]])\n",
    "\n",
    "def link_evidence(oof):\n",
    "    thresh = 1\n",
    "    idu = oof['id'].unique()\n",
    "    idc = idu[1]\n",
    "    eoof = oof[oof['class'] == \"Evidence\"]\n",
    "    neoof = oof[oof['class'] != \"Evidence\"]\n",
    "    for thresh2 in range(26,27, 1):\n",
    "        retval = []\n",
    "        for idv in idu:\n",
    "            for c in  ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement',\n",
    "                   'Counterclaim', 'Rebuttal']:\n",
    "                q = eoof[(eoof['id'] == idv) & (eoof['class'] == c)]\n",
    "                if len(q) == 0:\n",
    "                    continue\n",
    "                pst = []\n",
    "                for i,r in q.iterrows():\n",
    "                    pst = pst +[-1] + [int(x) for x in r['predictionstring'].split()]\n",
    "                start = 1\n",
    "                end = 1\n",
    "                for i in range(2,len(pst)):\n",
    "                    cur = pst[i]\n",
    "                    end = i\n",
    "                    #if pst[start] == 205:\n",
    "                    #   print(cur, pst[start], cur - pst[start])\n",
    "                    if (cur == -1 and c != 'Evidence') or ((cur == -1) and ((pst[i+1] > pst[end-1] + thresh) or (pst[i+1] - pst[start] > thresh2))):\n",
    "                        retval.append((idv, c, jn(pst, start, end)))\n",
    "                        start = i + 1\n",
    "                v = (idv, c, jn(pst, start, end+1))\n",
    "                #print(v)\n",
    "                retval.append(v)\n",
    "        roof = pd.DataFrame(retval, columns = ['id', 'class', 'predictionstring']) \n",
    "        roof = roof.merge(neoof, how='outer')\n",
    "        return roof\n",
    "\n",
    "proba_thresh = {\n",
    "    \"Lead\": 0.7,\n",
    "    \"Position\": 0.55,\n",
    "    \"Evidence\": 0.65,\n",
    "    \"Claim\": 0.55,\n",
    "    \"Concluding Statement\": 0.7,\n",
    "    \"Counterclaim\": 0.5,\n",
    "    \"Rebuttal\": 0.55,\n",
    "}\n",
    "\n",
    "min_thresh = {\n",
    "    \"Lead\": 9,\n",
    "    \"Position\": 5,\n",
    "    \"Evidence\": 14,\n",
    "    \"Claim\": 3,\n",
    "    \"Concluding Statement\": 11,\n",
    "    \"Counterclaim\": 6,\n",
    "    \"Rebuttal\": 4,\n",
    "}\n",
    "\n",
    "submission = []\n",
    "for sample_idx, sample in enumerate(test_samples):\n",
    "    preds = sample[\"preds\"]\n",
    "    offset_mapping = sample[\"offset_mapping\"]\n",
    "    sample_id = sample[\"id\"]\n",
    "    sample_text = sample[\"text\"]\n",
    "    sample_input_ids = sample[\"input_ids\"]\n",
    "    sample_pred_scores = sample[\"pred_scores\"]\n",
    "    sample_preds = []\n",
    "\n",
    "    if len(preds) < len(offset_mapping):\n",
    "        preds = preds + [\"O\"] * (len(offset_mapping) - len(preds))\n",
    "        sample_pred_scores = sample_pred_scores + [0] * (len(offset_mapping) - len(sample_pred_scores))\n",
    "    \n",
    "    idx = 0\n",
    "    phrase_preds = []\n",
    "    while idx < len(offset_mapping):\n",
    "        start, _ = offset_mapping[idx]\n",
    "        if preds[idx] != \"O\":\n",
    "            label = preds[idx][2:]\n",
    "        else:\n",
    "            label = \"O\"\n",
    "        phrase_scores = []\n",
    "        phrase_scores.append(sample_pred_scores[idx])\n",
    "        idx += 1\n",
    "        while idx < len(offset_mapping):\n",
    "            if label == \"O\":\n",
    "                matching_label = \"O\"\n",
    "            else:\n",
    "                matching_label = f\"I-{label}\"\n",
    "            if preds[idx] == matching_label:\n",
    "                _, end = offset_mapping[idx]\n",
    "                phrase_scores.append(sample_pred_scores[idx])\n",
    "                idx += 1\n",
    "            else:\n",
    "                break\n",
    "        if \"end\" in locals():\n",
    "            phrase = sample_text[start:end]\n",
    "            phrase_preds.append((phrase, start, end, label, phrase_scores))\n",
    "\n",
    "    temp_df = []\n",
    "    for phrase_idx, (phrase, start, end, label, phrase_scores) in enumerate(phrase_preds):\n",
    "        word_start = len(sample_text[:start].split())\n",
    "        word_end = word_start + len(sample_text[start:end].split())\n",
    "        word_end = min(word_end, len(sample_text.split()))\n",
    "        ps = \" \".join([str(x) for x in range(word_start, word_end)])\n",
    "        if label != \"O\":\n",
    "            if sum(phrase_scores) / len(phrase_scores) >= proba_thresh[label]:\n",
    "                if len(ps.split()) >= min_thresh[label]:\n",
    "                    temp_df.append((sample_id, label, ps))\n",
    "    \n",
    "    temp_df = pd.DataFrame(temp_df, columns=[\"id\", \"class\", \"predictionstring\"])\n",
    "    submission.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat(submission).reset_index(drop=True)\n",
    "submission = link_evidence(submission)\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snu36",
   "language": "python",
   "name": "snu36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
